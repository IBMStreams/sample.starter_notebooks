{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IBM Streams SPL Toolkits tutorial\n",
    "\n",
    "This tutorial demonstrates how to discover, use, build and launch SPL toolkits in a Python notebook.\n",
    "\n",
    "In this notebook, you'll see examples of how to:\n",
    "1. [Setup](#setup)\n",
    "2. [Discover Python packages](#discoverpypi)\n",
    "3. [Discover toolkits](#discovertoolkits)\n",
    "4. [Launch SPL main composite](#ghtksample)\n",
    "5. [Work with a microservice of a toolkit](#ghtk)\n",
    "6. [Integration of SPL operators in a Python topology](#splpy)\n",
    "\n",
    "# Overview\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "IBM Streams provides toolkits as reusable assets to get a solution faster.\n",
    "The build service contains product \"Out of the Box\" toolkits and in addition you can use \"Open Source\" toolkits from GitHub (https://github.com/IBMStreams) and Customer developed toolkits.\n",
    "Many product toolkits are open source toolkits. This tutorial shows how to find them and how to check for updates.\n",
    "\n",
    "You will also learn in this tutorial, how to use SPL operators in the Python API, and how to work with existing SPL application like samples and microservices.\n",
    "\n",
    "**How it works**\n",
    "   \n",
    "The Python applications created in this notebook are submitted to the IBM Streams service for execution.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "\n",
    "## Documentation\n",
    "    \n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"setup\"> </a> 1. Setup\n",
    "\n",
    "### 1.1 Add credentials for the IBM Streams service\n",
    "\n",
    "In order to submit a Streams application you need to provide the name of the Streams instance.\n",
    "\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icpd_core import icpd_util\n",
    "streams_instance_name = \"my-instance\" ## Change this to Streams instance\n",
    "cfg=icpd_util.get_service_instance_details(name=streams_instance_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Optional: Upgrade the `streamsx.toolkits` Python package\n",
    "\n",
    "Uncomment and run the cell below, if you want to upgrade to the latest version of the `streamsx.toolkits` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade streamsx.toolkits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python packages will be installed in the top of user path.<br/>\n",
    "If you have problem to get the latest version of python packages you can set the order of python packages manually to user path.<br/>\n",
    "you can find the user path with this command:<br/>\n",
    "`\n",
    "import sys\n",
    "for e in sys.path:\n",
    "    print(e)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import  the `streamsx.toolkits` package and verify the package version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx.toolkits as tkutils\n",
    "print(\"INFO: streamsx.toolkits package version: \" + tkutils.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"discoverpypi\"> </a> 2. Discover Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Discover installed Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installed_packages = tkutils.get_installed_packages()\n",
    "print (installed_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Discover latest version of Python packages on pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypi_packages = tkutils.get_pypi_packages()\n",
    "print (pypi_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check for updates of Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "\n",
    "for x in pypi_packages:\n",
    "    if x in installed_packages:\n",
    "        if installed_packages[x] != pypi_packages[x]:\n",
    "            print(Style.BRIGHT + Fore.BLACK + 'NEW VERSION ' + x \n",
    "                  + ': ' + Back.GREEN + pypi_packages[x] + Back.RESET)\n",
    "    else:\n",
    "        print(Fore.RED + 'NEW PACKAGE ' + x + ': ' + pypi_packages[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optional: Upgrade the Python package\n",
    "\n",
    "Uncomment and change the name `<NAME>` of the package name in the cell below.\n",
    "Run the cell below if you want to upgrade to the latest version of package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install --user --upgrade streamsx.<NAME>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"discovertoolkits\"> </a> 3. Discover Toolkits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Retrieve a list of toolkits available on the Streams build service\n",
    "\n",
    "This contains all product toolkits and custom toolkits that have been uploaded to the build service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_service_toolkits = tkutils.get_build_service_toolkits(cfg)\n",
    "print(build_service_toolkits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Retrieve a list of product toolkits on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_toolkits = tkutils.get_github_toolkits()\n",
    "print(github_toolkits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Check for toolkit updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "\n",
    "for x in github_toolkits:\n",
    "    if x in build_service_toolkits:\n",
    "        if build_service_toolkits[x] < github_toolkits[x]:\n",
    "            print(Style.BRIGHT + Fore.BLACK + 'NEW VERSION ' + x\n",
    "                  + ': ' + Back.GREEN + github_toolkits[x] + Back.RESET)\n",
    "    else:\n",
    "        print(Fore.RED + 'NEW TOOLKIT ' + x + ': ' + github_toolkits[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a newer version of a toolkit, you can download the toolkit from GitHub with the function\n",
    "`streamsx.toolkits.download_toolkit()` described here: https://streamsxtoolkits.readthedocs.io/en/latest/\n",
    "\n",
    "You can also upload a toolkit to the build service: https://streamsxtopology.readthedocs.io/en/stable/streamsx.build.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ghtksample\"> </a> 4. Launch SPL main composite\n",
    "\n",
    "This sample uses a toolkit from GitHub.\n",
    "* Downloads the toolkit\n",
    "* Selects a sample application as main composite\n",
    "* Builds and launches the application to the Streams instance \n",
    "\n",
    "### 4.1 Download the toolkit from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tk = tkutils.download_toolkit('com.ibm.streamsx.nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the samples directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $nlp_tk/../samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Select the sample application\n",
    "**Hint:** The main composite must be defined as `public composite <composite name>` to be used as a topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_app = nlp_tk + '/../samples/LemmatizerSample'\n",
    "main_composite_name = 'nlp.sample::LemmatizerSample'\n",
    "\n",
    "import streamsx.spl.op as op\n",
    "# here it is important, to include also the application, here 'sample_app', into the toolkits list:\n",
    "r = op.main_composite(kind=main_composite_name, toolkits=[sample_app, nlp_tk])\n",
    "# 'r' is a tuple containing the resulting Topology, and an Invoke of the main composite\n",
    "topo = r[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Submit the application\n",
    "\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "submission_result = context.submit(context.ContextTypes.DISTRIBUTED,\n",
    "                                   topo, \n",
    "                                   config=cfg)\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    print(\"JobId: \", submission_result['id'] , \"Name: \", submission_result['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 See job status\n",
    "\n",
    "You can view job status and logs by going to My Instances > Jobs. Find your job based on the id printed above. Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the Streams Console. Go to My Instances > Provisioned Instances. Select the Streams instance and open the URL listed under externalConsoleEndpoint or serviceConsoleEndpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Cancel the job\n",
    "\n",
    "This cell generates a widget you can use to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the Job object returned from \n",
    "`submission_result.job`.\n",
    "\n",
    "For example, use  `job.cancel()` to cancel the running job directly.\n",
    "\n",
    "## Summary\n",
    "\n",
    "We launched an existing SPL application with the Python API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ghtk\"> </a> 5. Work with a microservice of a toolkit\n",
    "\n",
    "This sample uses a toolkit from GitHub. The microservice is a part of the toolkit.\n",
    "* Downloads the toolkit\n",
    "* Selects a microservice application as main composite\n",
    "* Builds and launches the application to the Streams instance \n",
    "* Creates an application that uses the microservice.\n",
    "  It ingest tuples to the microservice and to receive the resulting tuples from the microservice.\n",
    "\n",
    "### 5.1 Download the toolkit from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tk = tkutils.download_toolkit('com.ibm.streamsx.nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Select the microservice application\n",
    "\n",
    "The nlp toolkits provides one microservice called `UimaService` that processes UIMA PEAR file.\n",
    "\n",
    "This microservice subscribes to the following topics.\n",
    "\n",
    "* `streamsx/nlp/documents` - ingest topic of type String\n",
    "* `streamsx/nlp/update/pear` - update pear topic of type String. String contains the filename of the pear file location.\n",
    "\n",
    "The following topic is published by the microservice:\n",
    "* `streamsx/nlp/annotations` - resulting annotations. Each tuple represents a processed document. Output is of type Json. CAS output is transformed to JSON and format depends on PEAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_microservice = 'com.ibm.streamsx.nlp.services::UimaService'\n",
    "\n",
    "import streamsx.spl.op as op\n",
    "\n",
    "r = op.main_composite(kind=nlp_microservice, toolkits=[nlp_tk])\n",
    "topo_nlp_microservice = r[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Submit the microservice application\n",
    "\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "submission_result_microservice = context.submit(context.ContextTypes.DISTRIBUTED,\n",
    "                                                topo_nlp_microservice,\n",
    "                                                config=cfg)\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result_microservice.job:\n",
    "    print(\"JobId: \", submission_result_microservice['id'], \"Name: \", submission_result_microservice['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Create an application to connect to the microservice\n",
    "\n",
    "This application generates documents to be processed by the \"UimaService\" and receives the output of the \"UimaService\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology.topology import Topology\n",
    "from streamsx.topology.schema import CommonSchema\n",
    "import time\n",
    "\n",
    "class StringData(object):\n",
    "    def __init__(self, count, delay=True):\n",
    "        self.count = count\n",
    "        self.delay = delay\n",
    "    def __call__(self):\n",
    "        if self.delay:\n",
    "            time.sleep(10)\n",
    "        doc = 'Text Sample\\n'+'April 4, 2019 Distillery Lunch Seminar UIMA and its Metadata 12:00PM-1:00PM in HAW GN-K35 \\n'+'April 16, 2019 KM & I Department Tea \\n'+'Title: An Eclipse-based TAE Configurator Tool \\n'+'3:00PM-4:30PM in HAW GN-K35 \\n'+'May 11, 2019 UIMA Tutorial \\n'+'9:00AM-5:00PM in HAW GN-K35 \\n'\n",
    "        for i in range(self.count):\n",
    "            yield doc + ' - doc_' + str(i)\n",
    "\n",
    "topo = Topology(\"NLPSample\")\n",
    "s = topo.source(StringData(1000)).as_string()\n",
    "s.publish(\"streamsx/nlp/documents\", schema=CommonSchema.String)\n",
    "    \n",
    "ts = topo.subscribe(\"streamsx/nlp/annotations\", schema=CommonSchema.Json)\n",
    "ts.print()\n",
    "ts.isolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Submit the application\n",
    "\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "submission_result_nlp_sample = context.submit(context.ContextTypes.DISTRIBUTED,\n",
    "                                              topo, \n",
    "                                              config=cfg)\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result_nlp_sample.job:\n",
    "    print(\"JobId: \", submission_result_nlp_sample['id'], \"Name: \", submission_result_nlp_sample['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 See job status\n",
    "\n",
    "You can view job status and logs by going to My Instances > Jobs. Find your job based on the id printed above. Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the Streams Console. Go to My Instances > Provisioned Instances. Select the Streams instance and open the URL listed under externalConsoleEndpoint or serviceConsoleEndpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Cancel the jobs\n",
    "\n",
    "The cells below generate a widget you can use to cancel the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel the job in the IBM Streams service\n",
    "submission_result_nlp_sample.cancel_job_button()\n",
    "\n",
    "# cancel the microservice job in the IBM Streams service\n",
    "submission_result_microservice.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the Job object returned from \n",
    "`submission_result_nlp_sample.job` and `submission_result_microservice.job`.\n",
    "\n",
    "For example, use  `job.cancel()` to cancel the running jobs directly.\n",
    "\n",
    "## Summary\n",
    "\n",
    "We launched an application with the Python API that works as microservice. We created an application to connect to this microservice with `publish` and `subsribe`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"splpy\"> </a> 6. Integration of SPL operators\n",
    "\n",
    "\n",
    "Integration of SPL operators:\n",
    "https://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.spl.op.html#\n",
    "\n",
    "\n",
    "### 6.1 Download the 'com.ibm.streamsx.nlp' toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tk = tkutils.download_toolkit('com.ibm.streamsx.nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Create sample application using SPL primitive operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_spl = Topology(\"WrapSPLOperatorsSample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are using a `Beacon` as source operator, which produces an infinite stream of tuples with the text *The cow jumps over the moon*.\n",
    "\n",
    "\n",
    "    stream<rstring document> Beacon = spl.utility::Beacon() {\n",
    "        param\n",
    "            initDelay: 5.0;\n",
    "            period: 0.01;\n",
    "        output Beacon: document=\"The cow jumps over the moon\";\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx.spl.op as op\n",
    "\n",
    "# Beacon operator is used to generate tuples with a single attribute of type rstring\n",
    "pulse = op.Source(topo_spl, kind='spl.utility::Beacon',\n",
    "                  schema='tuple<rstring document>',\n",
    "                  params={'initDelay': 5.0, 'period': 0.01})\n",
    "# output clause for the 'document' attribute of the output schema definition\n",
    "pulse.document = pulse.output('\"The cow jumps over the moon\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke operator (one input stream and one output stream)\n",
    "\n",
    "In SPL the invocation of the NgramBasic operator would look like below:\n",
    "\t\t\n",
    "        stream<map<rstring, uint32> ngramMap> NgramBasic = com.ibm.streamsx.nlp::NgramBasic (Beacon) {\n",
    "        \tparam\n",
    "\t\t\t\tdocumentAttribute: 'document';\n",
    "\t\t\t\tsize: 3u;\n",
    "\t\t\t\tminSize: 1u;\n",
    "\t\t\toutput NgramBasic: ngramMap = NgramCount();\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.spl.types import uint32\n",
    "from streamsx.spl.toolkit import add_toolkit\n",
    "\n",
    "ngrams = op.Invoke(topo_spl,\n",
    "                   inputs = [pulse.stream],\n",
    "                   kind = \"com.ibm.streamsx.nlp::NgramBasic\",\n",
    "                   schemas = 'tuple<map<rstring, uint32> ngramMap>',\n",
    "                   params = {'documentAttribute': 'document'})\n",
    "# there are different ways to specify operator parameters: use the params argument in the Invoke,\n",
    "# or use the params attribute of the resulting Invoke object:\n",
    "ngrams.params['size'] = uint32(3)\n",
    "ngrams.params['minSize'] = uint32(1)\n",
    "# assign the NgramCount() function to the 'ngramMap' attribute of the output stream 0:\n",
    "ngrams.ngramMap = ngrams.output(ngrams.outputs[0], 'NgramCount()')\n",
    "\n",
    "# Dump output stream to console log\n",
    "ngrams.outputs[0].print()\n",
    "\n",
    "add_toolkit(topo_spl, nlp_tk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Submit the application\n",
    "\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "submission_result_spl_sample = context.submit(context.ContextTypes.DISTRIBUTED,\n",
    "                                              topo_spl, \n",
    "                                              config=cfg)\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result_spl_sample.job:\n",
    "    print(\"JobId: \", submission_result_spl_sample['id'], \"Name: \",submission_result_spl_sample['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 See job status\n",
    "\n",
    "You can view job status and logs by going to My Instances > Jobs. Find your job based on the id printed above. Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the Streams Console. Go to My Instances > Provisioned Instances. Select the Streams instance and open the URL listed under externalConsoleEndpoint or serviceConsoleEndpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Cancel the job\n",
    "\n",
    "This cell generates a widget you can use to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel the job in the IBM Streams service\n",
    "submission_result_spl_sample.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the Job object returned from \n",
    "`submission_result_spl_sample.job`.\n",
    "\n",
    "For example, use  `job.cancel()` to cancel the running job directly.\n",
    "\n",
    "## Summary\n",
    "\n",
    "We used SPL operators with the Python Topology API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
