{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IBM Streams sample application\n",
    "\n",
    "This sample demonstrates creating a Streams Python application to perform some analytics, and viewing the results.\n",
    "\n",
    "In this notebook, you'll see examples of how to :\n",
    " 1. [Setup your data connections](#setup)\n",
    " 2. [Create the application](#create)\n",
    " 3. [Submit the application](#launch)\n",
    " 4. [Connect to the running application to view data](#view)\n",
    " 5. [Stop the application](#cancel)\n",
    "\n",
    "# Overview\n",
    "\n",
    "**About the sample**\n",
    "\n",
    "This application simulates a data hub that receives readings from sensors. It computes the 30 second rolling average of the reported readings using [Pandas](https://pandas.pydata.org/).  \n",
    "\n",
    "**How it works**\n",
    "   \n",
    "The Python application created in this notebook is submitted to the IBM Streams service for execution. Once the application is running in the service, you can connect to it from the notebook to retrieve the results.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"setup\"></a>\n",
    "# 1. Setup\n",
    "### 1.1 Add credentials for the IBM Streams service\n",
    "\n",
    "With the cell below selected, click the \"Connect to instance\" button in the toolbar to insert the credentials for the service.\n",
    "\n",
    "<a target=\"blank\" href=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/02/connect_icp4d.gif\">See an example</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify `streamsx` package version\n",
    "\n",
    "Run the cell below to check which version of the `streamsx` package is installed.  \n",
    "\n",
    "If you need to upgrade, use\n",
    "\n",
    "- `import sys`\n",
    "- `!{sys.executable} -m pip install --user --upgrade streamsx` to upgrade the package.\n",
    "- Or, use  `!{sys.executable} -m pip install --user streamsx==somever` to install a specific version of the package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx.topology.context\n",
    "print(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\n",
    "\n",
    "#For more details uncomment line below.\n",
    "#!pip show streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "# 2. Create the application\n",
    "This application is going to ingest readings from simulated sensors and compute the 30 second rolling average value for each sensor.  \n",
    "\n",
    "All Streams applications start with  a `Topology` object, so start by creating one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology.topology import Topology\n",
    "\n",
    "topo = Topology(name=\"SensorAverages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define sources\n",
    "Your application needs some data to analyze, so the first step is to define a data source that produces the data being processed. \n",
    "\n",
    "Next, use the data source to create a `Stream` object. A `Stream` is a potentially infinite sequence of tuples containing the data to be analyzed.\n",
    "\n",
    "Tuples are Python objects by default. Other supported formats include JSON. [See the doc for all supported formats](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#stream)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Define a source class\n",
    "\n",
    "Define a callable class that will produce the data to be analyzed.\n",
    "\n",
    "This example class produces readings from sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define a callable source \n",
    "class SensorReadingsSource(object):\n",
    "    def __call__(self):\n",
    "        # This is just an example of using generated data, \n",
    "        # Here you could connect to db\n",
    "        # generate data\n",
    "        # connect to data set\n",
    "        # open file\n",
    "        while True:\n",
    "            time.sleep(0.001)\n",
    "            sensor_id = random.randint(1,100)\n",
    "            reading = {}\n",
    "            reading [\"sensor_id\"] = \"sensor_\" + str(sensor_id)\n",
    "            reading [\"value\"] =  random.random() * 3000\n",
    "            reading[\"ts\"] = int((datetime.now().timestamp())) \n",
    "            yield reading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2  Create the `Stream `\n",
    "\n",
    "Create a `Stream` called  `readings` that will contain the simulated data that `SensorReadingsSource` produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a stream from the data using Topology.source\n",
    "readings = topo.source(SensorReadingsSource(), name=\"Readings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Analyze data\n",
    "\n",
    "Use a variety of methods in the `Stream` class to analyze your in-flight data, including applying machine learning models.\n",
    "\n",
    "See the [common operations section](https://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide-4/) of the developer guide and the [documentation on the Stream class](https://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#streamsx.topology.topology.Stream) for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Filter data from the  `Stream`  \n",
    "\n",
    "Use `Stream.filter()` to remove data that doesn't match a certain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept only values greater than 100\n",
    "\n",
    "valid_readings = readings.filter(lambda x : x[\"value\"] > 100,\n",
    "                                 name=\"ValidReadings\")\n",
    "\n",
    "# You could create another stream of the invalid data:\n",
    "# invalid_readings = readings.filter(lambda x : x[\"value\"] <= 100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2  Compute averages on the  `Stream`  \n",
    "\n",
    "Define a function to compute the 30 second rolling average for the readings.\n",
    "\n",
    "Steps are outlined in the code below.\n",
    "See the [Window class documentation](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#streamsx.topology.topology.Window)  for details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define aggregation function\n",
    "    \n",
    "def average_reading(items_in_window):\n",
    "    df = pd.DataFrame(items_in_window)\n",
    "    readings_by_id = df.groupby(\"sensor_id\")\n",
    "    \n",
    "    averages = readings_by_id[\"value\"].mean()\n",
    "    period_end = df[\"ts\"].max()\n",
    "\n",
    "    result = []\n",
    "    for id, avg in averages.iteritems():\n",
    "        result.append({\"average\": avg,\n",
    "                \"sensor_id\": id,\n",
    "                \"period_end\": time.ctime(period_end)})\n",
    "               \n",
    "    return result\n",
    "\n",
    "# 2. Define window: e.g. a 30 second rolling average, updated every second\n",
    "\n",
    "interval = timedelta(seconds=30)\n",
    "window = valid_readings.last(size=interval).trigger(when=timedelta(seconds=1))\n",
    "\n",
    "\n",
    "# 3. Pass aggregation function to Window.aggregate\n",
    "# average_reading returns a list of the averages for each sensor,\n",
    "# use flat map to convert it to individual tuples, one per sensor\n",
    "rolling_average = window.aggregate(average_reading).flat_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Create a `View` to preview the tuples on the `Stream` \n",
    "\n",
    "\n",
    "A `View` is a connection to a `Stream` that becomes activated when the application is running. We examine the data from within the notebook in section 4, below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_view = rolling_average.view(name=\"RollingAverage\", description=\"Sample of rolling averages for each sensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Define output\n",
    "\n",
    "The `rolling_average` stream is our final result.  We will use `Stream.publish()` to make this stream available to other applications. \n",
    "\n",
    "If you want to send the stream to another database or system, you would use a sink function (similar to the source function) and invoke it using `Stream.for_each`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# publish results as JSON\n",
    "rolling_average.publish(topic=\"AverageReadings\",\n",
    "                        schema=json, \n",
    "                        name=\"PublishAverage\")\n",
    "\n",
    "# Other options include:\n",
    "# invoke another sink function:\n",
    "# rolling_average.for_each(func=send_to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"launch\"></a>\n",
    "\n",
    "# 3. Submit the application\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "# submit the topology 'topo'\n",
    "submission_result = context.submit (\"DISTRIBUTED\", topo, config = cfg)\n",
    "\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    streams_job = submission_result.job\n",
    "    print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"view\"></a>\n",
    "\n",
    "# 4. Use a `View` to access data from the job\n",
    "Now that the job is started, use the `View` object you created in step 2.3 to start retrieving data from a `Stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the view and display the data\n",
    "queue = averages_view.start_data_fetch()\n",
    "try:\n",
    "    for val in range(10):\n",
    "        print(queue.get())    \n",
    "finally:\n",
    "    averages_view.stop_data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Display the results in real time\n",
    "Calling `View.display()` from the notebook displays the results of the view in a table that is updated in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for 30 seconds\n",
    "averages_view.display(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 See job status \n",
    "\n",
    "You can view job status and logs by going to **My Instances** > **Jobs**. Find your job based on the id printed above.\n",
    "Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the Streams Console.  Go to **My Instances** > **Provisioned Instances**. Select the Streams instance and open the URL listed under *externalConsoleEndpoint* or *serviceConsoleEndpoint*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cancel\"></a>\n",
    "\n",
    "# 5. Cancel the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell generates a widget you can use to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the [Job](https://streamsxtopology.readthedocs.io/en/stable/streamsx.rest_primitives.html#streamsx.rest_primitives.Job) object returned from `submission_result.job`\n",
    "\n",
    "For example, use `job.cancel()` to cancel the running job directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We started with a `Stream` called `readings`, which contained the data we wanted to analyze. Next, we used functions in the `Stream` object to perform simple analysis and produced the `rolling_average` stream.  This stream is `published` for other applications running within our Streams instance to access.\n",
    "\n",
    "After submitting the application to the Streams service, we connected to the `rolling_average` view to see the results within the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
