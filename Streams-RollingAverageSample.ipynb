{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IBM Streams sample application\n",
    "\n",
    "This sample demonstrates creating a Streams Python application to perform some analytics, and viewing the results.\n",
    "\n",
    "In this notebook, you'll see examples of how to :\n",
    " 1. [Setup your data connections](#setup)\n",
    " 2. [Create the application](#create)\n",
    " 3. [Submit the application](#launch)\n",
    " 4. [Connect to the running application to view data](#view)\n",
    " 5. [Stop the application](#cancel)\n",
    "\n",
    "# Overview\n",
    "\n",
    "**About the sample**\n",
    "\n",
    "This application simulates a data hub that receives readings from sensors. It computes the 30 second rolling average of the reported readings using [Pandas](https://pandas.pydata.org/).  \n",
    "\n",
    "**How it works**\n",
    "   \n",
    "The Python application created in this notebook is submitted to the IBM Streams service for execution. Once the application is running in the service, you can connect to it from the notebook to retrieve the results.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "\n",
    "### Documentation\n",
    "\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"setup\"></a>\n",
    "# 1.  Build setup\n",
    "\n",
    "Streams Python applications or topologies can be executed in multiple scenarios, such as from a notebook running within an IBM Cloud Pak for Data project, or a standalone application connecting to a local installation.\n",
    "\n",
    "In each case, you have to connect to the Streams instance to submit the application for execution.\n",
    "However, the information required to connect to the instance depends on the scenario. \n",
    "\n",
    "Therefore, choose the scenario from the list below that matches your target Streams installation and use the code snippets provided to connect to the instance. \n",
    "\n",
    "Each snippet will also set the [`contextType`](https://streamsxtopology.readthedocs.io/en/latest/streamsx.topology.context.html#streamsx.topology.context.ContextTypes) which determines the execution context.\n",
    "\n",
    "-  Run on a Streams service in IBM Cloud Pak for Data\n",
    "    - [From a project](#cpd_1)\n",
    "    - [Without a project](#cpd_2)\n",
    "- [Run on a standalone Streams installation (v5.2+, installed via Kubernetes)](#edge)\n",
    "- [Run on the Streaming Analytics service on IBM Cloud](#sas)\n",
    "- [Run on a local installation of Streams v4.2 or v4.3](#v4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cpd_1\"></a>\n",
    "\n",
    "### 1.1.1a Option 1:  Submit to Streams on IBM Cloud Pak for Data  from a project\n",
    "In this context you need to provide the name of the Streams instance.\n",
    "\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icpd_core import icpd_util\n",
    "from streamsx.topology import context\n",
    "\n",
    "streams_instance_name = \"sample-streams\" ## Change this to Streams instance\n",
    "\n",
    "cfg=icpd_util.get_service_instance_details(name=streams_instance_name)\n",
    "\n",
    "# This specifies how the application will be deployed\n",
    "contextType = context.ContextTypes.DISTRIBUTED\n",
    "\n",
    "\n",
    "print(\"Saved credentials, continue to section 1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cpd_2\"></a>\n",
    "### 1.1.1b Option 1b:    Submit to Streams on Cloud Pak for Data *without* a Cloud Pak for Data project  \n",
    "\n",
    "Collect the following environment information. Set the values for each variable where indicated in the following cell.\n",
    "\n",
    "- `CP4D_URL` - Cloud Pak for Data deployment URL, e.g. `https://cp4d_server:31843`. \n",
    "\n",
    "- `STREAMS_INSTANCE_ID`:\n",
    "    1. From the navigation menu, click **My instances**.\n",
    "    2. Click the **Provisioned Instances** tab.\n",
    "    3. Select the Streams instance you want to use, and set the value of `STREAMS_INSTANCE_ID` in the cell below to the name of the instance.\n",
    "\n",
    "- `STREAMS_USERNAME` - (optional) User name to submit the job as, defaulting to the current operating system user name.\n",
    "- `STREAMS_PASSWORD` - Password for authentication.\n",
    "\n",
    "Contact your administrator for details.\n",
    "\n",
    "If you are using a username and password to authenticate, enter them when prompted, otherwise delete those lines before running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streams username········\n",
      "Streams password········\n",
      "Saved credentials, continue to section 1.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from streamsx.topology import context\n",
    "cfg ={}\n",
    "\n",
    "CP4D_URL = # Paste URL here\n",
    "STREAMS_INSTANCE_ID =  # Paste URL here\"\n",
    "\n",
    "os.environ[\"STREAMS_INSTANCE_ID\"]= STREAMS_INSTANCE_ID\n",
    "os.environ[\"CP4D_URL\"]= CP4D_URL\n",
    "os.environ[\"STREAMS_USERNAME\"]= getpass.getpass(\"Streams username\")\n",
    "os.environ[\"STREAMS_PASSWORD\"]= getpass.getpass(\"Streams password\")\n",
    "\n",
    "# This specifies how the application will be deployed\n",
    "contextType = context.ContextTypes.DISTRIBUTED\n",
    "\n",
    "print(\"Saved credentials, continue to section 1.2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"edge\"></a>\n",
    "### 1.1.2 Option 2:    Submit to a  Standalone Streams installation\n",
    "In order to submit a Streams application you need the following information from the Streams instance\n",
    "\n",
    "- `STREAMS_BUILD_URL` - Streams build service URL, e.g. when the service is exposed as node port: `https://<NODE-IP>:<NODE-PORT>`\n",
    "- `STREAMS_REST_URL` - Streams SWS service (REST API) URL, e.g. when the service is exposed as node port: `https://<NODE-IP>:<NODE-PORT>`\n",
    "- `STREAMS_USERNAME` - (optional) User name to submit the job as, defaulting to the current operating system user name.\n",
    "- `STREAMS_PASSWORD` - Password for authentication.\n",
    "\n",
    "The documentation has the steps to retrieve the URLs for the Build and REST service.\n",
    "Set the values for each variable where indicated in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streams username········\n",
      "Streams password········\n",
      "Saved credentials, continue to section 1.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from streamsx.topology import context\n",
    "cfg = {}\n",
    "STREAMS_BUILD_URL =  # Paste URL here\n",
    "STREAMS_REST_URL =  #  # Paste URL here\n",
    "os.environ[\"STREAMS_REST_URL\"]= STREAMS_REST_URL\n",
    "os.environ[\"STREAMS_BUILD_URL\"]= STREAMS_BUILD_URL\n",
    "os.environ[\"STREAMS_USERNAME\"]= getpass.getpass(\"Streams username\")\n",
    "os.environ[\"STREAMS_PASSWORD\"]= getpass.getpass(\"Streams password\")\n",
    "\n",
    "# This specifies how the application will be deployed\n",
    "contextType = context.ContextTypes.DISTRIBUTED\n",
    "\n",
    "print(\"Saved credentials, continue to section 1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sas\"></a>\n",
    "### 1.1.3 Option 3:    Submit to the Streaming Analytics service\n",
    "To connect to the Streaming Analytics service in IBM cloud you need the **service instance name** and the **service credentials**.\n",
    "Retrieve your service name and credentials from the Streaming Analytics service dashboard.\n",
    "\n",
    "- Service instance name: This is the name of the service instance, at the top  of the service dashboard.\n",
    "- Service credentials: To copy your service credentials, open the Streaming Analytics service dashboard click **Service Credentials**, then **View Credentials**, and copy the contents of the cell. Click **Add new credentials** if there are no credentials listed.\n",
    "\n",
    "See the image below for an example. Click to enlarge.\n",
    "<a href=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/11/copycredentials.png\">\n",
    "<img width=\"600\" height=\"500\" src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/11/copycredentials.png\"></a>\n",
    "\n",
    "Run the following cells and enter the name and credentials when prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify this cell\n",
    "SA_credentials = None\n",
    "service_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved credentials, continue to section 1.2\n"
     ]
    }
   ],
   "source": [
    "from streamsx.topology.context import ConfigParams\n",
    "from streamsx.topology import context\n",
    "\n",
    "import getpass\n",
    "if  SA_credentials is None: \n",
    "    SA_credentials=getpass.getpass('Streaming Analytics credentials:')\n",
    "    service_name =input('Streaming Analytics name:')\n",
    "\n",
    "vs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (SA_credentials)}]}\n",
    "cfg = {}\n",
    "cfg[ConfigParams.VCAP_SERVICES] = vs\n",
    "cfg[ConfigParams.SERVICE_NAME] = service_name\n",
    "\n",
    "# This specifies how the application will be deployed\n",
    "\n",
    "contextType = context.ContextTypes.STREAMING_ANALYTICS_SERVICE\n",
    "print(\"Saved credentials, continue to section 1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"v4\"></a>\n",
    "### 1.1.4 Option 4:    Submit to  Streams v4.2 or v4.3\n",
    "\n",
    "If you are using the Streams Quick Start Edition, you do not have to do any further configuration. \n",
    "\n",
    "Otherwise, make sure that the `STREAMS_INSTANCE_ID` and `STREAMS_DOMAIN_ID` are set as environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if needed\n",
    "# STREAMS_INSTANCE_ID = # Set instance ID\n",
    "# STREAMS_DOMAIN_ID = # Set domain ID\n",
    "# os.environ[\"STREAMS_INSTANCE_ID\"]= STREAMS_INSTANCE_ID\n",
    "# os.environ[\"STREAMS_DOMAIN_ID\"]= STREAMS_DOMAIN_ID\n",
    "# This specifies how the application will be deployed\n",
    "contextType = context.ContextTypes.DISTRIBUTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify `streamsx` package version\n",
    "\n",
    "Run the cell below to check which version of the `streamsx` package is installed.  \n",
    "\n",
    "If you need to upgrade, use\n",
    "\n",
    "- `import sys`\n",
    "- `!{sys.executable} -m pip install --user --upgrade streamsx` to upgrade the package.\n",
    "- Or, use  `!{sys.executable} -m pip install --user streamsx==somever` to install a specific version of the package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: streamsx package version: 1.13.14\n"
     ]
    }
   ],
   "source": [
    "import streamsx.topology.context\n",
    "print(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\n",
    "#For more details uncomment line below.\n",
    "#!pip show streamsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "# 2. Create the application\n",
    "This application is going to ingest readings from simulated sensors and compute the 30 second rolling average value for each sensor.  \n",
    "\n",
    "All Streams applications start with  a `Topology` object, so start by creating one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology.topology import Topology\n",
    "\n",
    "topo = Topology(name=\"SensorAverages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define sources\n",
    "Your application needs some data to analyze, so the first step is to define a data source that produces the data being processed. \n",
    "\n",
    "Next, use the data source to create a `Stream` object. A `Stream` is a potentially infinite sequence of tuples containing the data to be analyzed.\n",
    "\n",
    "Tuples are Python objects by default. Other supported formats include JSON. [See the doc for all supported formats](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#stream)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Define a source class\n",
    "\n",
    "Define a callable class that will produce the data to be analyzed.\n",
    "\n",
    "This example class produces readings from sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define a callable source \n",
    "class SensorReadingsSource(object):\n",
    "    def __call__(self):\n",
    "        # This is just an example of using generated data, \n",
    "        # Here you could connect to db\n",
    "        # generate data\n",
    "        # connect to data set\n",
    "        # open file\n",
    "        while True:\n",
    "            time.sleep(0.001)\n",
    "            sensor_id = random.randint(1,100)\n",
    "            reading = {}\n",
    "            reading [\"sensor_id\"] = \"sensor_\" + str(sensor_id)\n",
    "            reading [\"value\"] =  random.random() * 3000\n",
    "            reading[\"ts\"] = int((datetime.now().timestamp())) \n",
    "            yield reading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2  Create the `Stream `\n",
    "\n",
    "Create a `Stream` called  `readings` that will contain the simulated data that `SensorReadingsSource` produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a stream from the data using Topology.source\n",
    "readings = topo.source(SensorReadingsSource(), name=\"Readings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Analyze data\n",
    "\n",
    "Use a variety of methods in the `Stream` class to analyze your in-flight data, including applying machine learning models.\n",
    "\n",
    "See the [common operations section](https://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide-4/) of the developer guide and the [documentation on the Stream class](https://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#streamsx.topology.topology.Stream) for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Filter data from the  `Stream`  \n",
    "\n",
    "Use `Stream.filter()` to remove data that doesn't match a certain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept only values greater than 100\n",
    "\n",
    "valid_readings = readings.filter(lambda x : x[\"value\"] > 100,\n",
    "                                 name=\"ValidReadings\")\n",
    "\n",
    "# You could create another stream of the invalid data:\n",
    "# invalid_readings = readings.filter(lambda x : x[\"value\"] <= 100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2  Compute averages on the  `Stream`  \n",
    "\n",
    "Define a function to compute the 30 second rolling average for the readings.\n",
    "\n",
    "Steps are outlined in the code below.\n",
    "See the [Window class documentation](http://ibmstreams.github.io/streamsx.topology/doc/pythondoc/streamsx.topology.topology.html#streamsx.topology.topology.Window)  for details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define aggregation function\n",
    "    \n",
    "def average_reading(items_in_window):\n",
    "    df = pd.DataFrame(items_in_window)\n",
    "    readings_by_id = df.groupby(\"sensor_id\")\n",
    "    \n",
    "    averages = readings_by_id[\"value\"].mean()\n",
    "    period_end = df[\"ts\"].max()\n",
    "\n",
    "    result = []\n",
    "    for id, avg in averages.iteritems():\n",
    "        result.append({\"average\": avg,\n",
    "                \"sensor_id\": id,\n",
    "                \"period_end\": time.ctime(period_end)})\n",
    "               \n",
    "    return result\n",
    "\n",
    "# 2. Define window: e.g. a 30 second rolling average, updated every second\n",
    "\n",
    "interval = timedelta(seconds=30)\n",
    "window = valid_readings.last(size=interval).trigger(when=timedelta(seconds=1))\n",
    "\n",
    "\n",
    "# 3. Pass aggregation function to Window.aggregate\n",
    "# average_reading returns a list of the averages for each sensor,\n",
    "# use flat map to convert it to individual tuples, one per sensor\n",
    "rolling_average = window.aggregate(average_reading).flat_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Create a `View` to preview the tuples on the `Stream` \n",
    "\n",
    "\n",
    "A `View` is a connection to a `Stream` that becomes activated when the application is running. We examine the data from within the notebook in section 4, below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_view = rolling_average.view(name=\"RollingAverage\", description=\"Sample of rolling averages for each sensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Define output\n",
    "\n",
    "The `rolling_average` stream is our final result.  We will use `Stream.publish()` to make this stream available to other applications. \n",
    "\n",
    "If you want to send the stream to another database or system, you would use a sink function (similar to the source function) and invoke it using `Stream.for_each`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<streamsx.topology.topology.Sink at 0x7f045c70c668>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# publish results as JSON\n",
    "rolling_average.publish(topic=\"AverageReadings\",\n",
    "                        schema=json, \n",
    "                        name=\"PublishAverage\")\n",
    "\n",
    "# Other options include:\n",
    "# invoke another sink function:\n",
    "# rolling_average.for_each(func=send_to_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"launch\"></a>\n",
    "\n",
    "# 3. Submit the application\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting to DISTRIBUTED context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n",
      "Insecure host connections enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId:  9 \n",
      "Job name:  notebook::SensorAverages_9\n"
     ]
    }
   ],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "print(\"Submitting to \" + contextType  + \" context\")\n",
    "# submit the topology 'topo'\n",
    "submission_result = context.submit (contextType, topo, config = cfg)\n",
    "\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    streams_job = submission_result.job\n",
    "    print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"view\"></a>\n",
    "\n",
    "# 4. Use a `View` to access data from the job\n",
    "Now that the job is started, use the `View` object you created in step 2.3 to start retrieving data from a `Stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average': 1401.0884850389868, 'sensor_id': 'sensor_1', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1354.7456766554853, 'sensor_id': 'sensor_10', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1823.6135796171936, 'sensor_id': 'sensor_100', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1617.1620805690814, 'sensor_id': 'sensor_11', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1821.7990644663246, 'sensor_id': 'sensor_12', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1538.6331621586512, 'sensor_id': 'sensor_13', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1516.803832278493, 'sensor_id': 'sensor_14', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1450.0449833862046, 'sensor_id': 'sensor_15', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1532.283679450917, 'sensor_id': 'sensor_16', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n",
      "{'average': 1519.6040973560582, 'sensor_id': 'sensor_17', 'period_end': 'Mon Nov 11 22:21:31 2019'}\n"
     ]
    }
   ],
   "source": [
    "# Connect to the view and display the data\n",
    "queue = averages_view.start_data_fetch()\n",
    "try:\n",
    "    for val in range(10):\n",
    "        print(queue.get())    \n",
    "finally:\n",
    "    averages_view.stop_data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Display the results in real time\n",
    "Calling `View.display()` from the notebook displays the results of the view in a table that is updated in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for 30 seconds\n",
    "averages_view.display(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 See job status \n",
    "\n",
    "#### View job status in IBM Cloud Pak for Data\n",
    "You can view job status and logs by going to **My Instances** > **Jobs**. Find your job based on the id printed above.\n",
    "Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the graph. Go to **My Instances** > **Jobs**. Select \"View graph\" action for the running job.\n",
    "\n",
    "#### View job status in other Streams installations\n",
    "\n",
    "- Open the Streams Console. \n",
    "    - **IBM Cloud**: Open the service instance page and click **Launch**.\n",
    "    - **Standalone Streams instance in IBM Cloud Pak for Data**: Get the URL from the documentation.\n",
    "    - **Local Streams installation**: `streamtool geturl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cancel\"></a>\n",
    "\n",
    "# 5. Cancel the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell generates a widget you can use to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the [Job](https://streamsxtopology.readthedocs.io/en/stable/streamsx.rest_primitives.html#streamsx.rest_primitives.Job) object returned from `submission_result.job`\n",
    "\n",
    "For example, use `job.cancel()` to cancel the running job directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We started with a `Stream` called `readings`, which contained the data we wanted to analyze. Next, we used functions in the `Stream` object to perform simple analysis and produced the `rolling_average` stream.  This stream is `published` for other applications running within our Streams instance to access.\n",
    "\n",
    "After submitting the application to the Streams service, we connected to the `rolling_average` view to see the results within the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
