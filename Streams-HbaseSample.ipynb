{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Streams HBASE sample application\n",
    "This sample demonstrates creating a Streams Python application to connect to HBASE, perform some operations on a table, and viewing the results.\n",
    "\n",
    "In this notebook, you'll see examples of how to:\n",
    "- [Setup](#setup)\n",
    "- [Create HBASE credentials](#credentials)\n",
    "- [Create the application](#create)\n",
    "- [Submit the application](#submit)\n",
    "- [Connect to the running application to view data](#view)\n",
    "\n",
    "# Overview\n",
    "**About the sample**\n",
    "\n",
    "This application simulates data tuples that are inserted into a HBASE table and get all rows from the table.\n",
    "\n",
    "**How it works**\n",
    "   \n",
    "The Python application created in this notebook is submitted to the IBM Streams service for execution. Once the application is running in the service, you can connect to it from the notebook to retrieve the results.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "\n",
    "### Documentation\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [Streams Python API](https://streamsxtopology.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"setup\"> </a> 1. Setup\n",
    "\n",
    "### 1.1 Add credentials for the IBM Streams service\n",
    "\n",
    "In order to submit a Streams application you need to provide the name of the Streams instance.\n",
    "\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icpd_core import icpd_util\n",
    "streams_instance_name = \"my-instance\" ## Change this to Streams instance\n",
    "cfg=icpd_util.get_service_instance_details(name=streams_instance_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Optional: Upgrade the `streamsx.hbase` Python package\n",
    "\n",
    "Uncomment and run the cell below, if you want to upgrade to the latest version of the `streamsx.hbase` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!pip install --user --upgrade streamsx\n",
    "#!pip install --user --upgrade streamsx.hbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python packages will be installed in the top of user path.<br/>\n",
    "If you have problem to get the latest version of python packages you can set the order of python packages manually to user path.<br/>\n",
    "you can find the user path with this command:<br/>\n",
    "`\n",
    "import sys\n",
    "for e in sys.path:\n",
    "    print(e)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx.hbase as hb\n",
    "import streamsx.topology.context\n",
    "print(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\n",
    "print(\"INFO: streamsx.hbase package version: \" + hb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"credentials\"> </a> 1.3 Configure the connection to HBASE\n",
    "\n",
    "Perform the steps [Connecting to data source](https://docs-icpdata.mybluemix.net/docs/content/SSQNUZ_current/com.ibm.icpdata.doc/igc/t_connect_data_sources.html) \n",
    "and create an external configuration for your HBASE connection.\n",
    "\n",
    "1. Select as connection type \"HDFS-HDP\"\n",
    "2. Enter HDFS \"host\" and \"port\"\n",
    "3. Set the field \"WebHDFSUrl\" to None since it is not required for HBASE. \n",
    "\n",
    "Update the name in the cell below according to your connection name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_name = 'HBASE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbase_connection=icpd_util.get_connection(connection_name, conn_class='external')\n",
    "print (hbase_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"create\"> </a> 2. Create the application\n",
    "All Streams applications start with a Topology object, so start by creating one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from streamsx.topology.topology import *\n",
    "from streamsx.topology.context import *\n",
    "from streamsx.topology.schema import StreamSchema\n",
    "import streamsx.hbase as hbase\n",
    "import json\n",
    "\n",
    "\n",
    "# create a Topology object\n",
    "topo = Topology(name=\"hbase\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### How to use the streamsx.hbase package\n",
    "\n",
    "The streamsx.hbase package is the Python wrapper for the [streamsx.hbase](https://ibmstreams.github.io/streamsx.hbase/doc/spldoc/html) toolkit\n",
    "\n",
    "Python package documentation: http://streamsxhbase.readthedocs.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"insert\"> </a> 2.2. Insert streaming data into the table\n",
    "\n",
    "Next, we generate a stream of data and insert it into the table we created.<br/>\n",
    "But befor we start the application, we have to create an HBASE test table on our hadoop server.<br/>\n",
    "The table name is in our test is: `streamsSample_lotr` (lord of the rings). <br/>\n",
    "Login to the hadoop server and start the hbase shell tool and create a table. <br/>\n",
    "```\n",
    "hbase shell\n",
    "create 'streamsSample_lotr','appearance','location'\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'streamsSample_lotr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step we put some rows into HBASE table. <br/>\n",
    "The function `_create_stream_for_put` creates a stream that contains 10 rows. <br/> \n",
    "The function `hbase.put` gets the streams `putStream` as input and inserts created rows into HBASE Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_stream_for_put(topo):\n",
    "    putStream = topo.source([0,1,2,3,4,5,6,7,8,9])\n",
    "    schema=StreamSchema('tuple<int32 id, rstring character, rstring colF, rstring colQ, rstring value>').as_tuple()\n",
    "    return putStream.map(lambda x : (x,'Gandalf_' + str(x), 'location','beginTwoTowers', 'travelling'), schema=schema)\n",
    "\n",
    "putStream = _create_stream_for_put(topo) \n",
    "put_rows = hbase.put(putStream, table_name=table_name, connection=hbase_connection)\n",
    "put_rows.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"get\"> </a> 2.3. get data from the table\n",
    "Now we get rows from the table. <br/>\n",
    "The function `_create_query_stream_for_get` creates a stream that contains queries. <br/>\n",
    "The function `hbase.get` gets `getStrem` as input stream and returns selected rows. <br/>\n",
    "The parameter `row_attr_name` specifies the name of the attribute on the input tuple containing the columnFamily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_query_stream_for_get(topo):\n",
    "    getStream = topo.source([0,1,2,3,4,5,6,7,8,9])\n",
    "    schema=StreamSchema('tuple<int32 id, rstring who, rstring infoType, rstring requestedDetail>').as_tuple()\n",
    "    return getStream.map(lambda x : (x,'Gandalf_' + str(x), 'location','beginTwoTowers'), schema=schema)\n",
    "\n",
    "getStream = _create_query_stream_for_get(topo) \n",
    "get_rows = hbase.get(getStream, table_name=table_name, row_attr_name=\"who\", connection=hbase_connection, name=\"HbaseGet\")\n",
    "get_rows.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"scan\"> </a> 2.4. scan all rows from the table\n",
    "In the next step we scan all rows from the table.<br/>\n",
    "The function `hbase.scan` returns all rows from the HBASE table.<br/>\n",
    "This parameter `init_delay` specifies the time to wait in seconds before the operator scans the rows. <br/>\n",
    "This parameter `max_versions` specifies the maximum number of versions that the operator returns. It defaults to a value of one. A value of 0 indicates that the operator gets all versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_rows = hbase.scan(topo, table_name=table_name, max_versions=0 , init_delay=10, connection=hbase_connection, name=\"HbaseScan\")\n",
    "scanned_rows.print()\n",
    "\n",
    "\n",
    "# create a view to check retrieving rows from a table\n",
    "scannedView = scanned_rows.view(name=\"scannedRows\", description=\"scanned rows from HBASE table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"submit\"> </a> 3. Submit the application\n",
    "\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsx.topology import context\n",
    "\n",
    "# Disable SSL certificate verification if necessary\n",
    "cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "# submit the topology 'topo'\n",
    "submission_result = context.submit (\"DISTRIBUTED\", topo, config = cfg)\n",
    "\n",
    "# The submission_result object contains information about the running application, or job\n",
    "if submission_result.job:\n",
    "    streams_job = submission_result.job\n",
    "    print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"view\"> </a> 4. View data from the table\n",
    "Now that the job is started, use the View object you have already created to start retrieving rows from a HBASE table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the view and display the selected data\n",
    "queue = scannedView.start_data_fetch()\n",
    "try:\n",
    "    for val in range(20):\n",
    "        print(queue.get())    \n",
    "finally:\n",
    "    scannedView.stop_data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"status\"> </a> 5. See job status\n",
    "\n",
    "You can view job status and logs by going to My Instances > Jobs. Find your job based on the id printed above. Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the Streams Console. Go to My Instances > Provisioned Instances. Select the Streams instance and open the URL listed under externalConsoleEndpoint or serviceConsoleEndpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"cancel\"></a> 6. Cancel the job\n",
    "\n",
    "This cell generates a widget you can use to cancel the job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the Job object returned from \n",
    "`submission_result.job`.\n",
    "\n",
    "For example, use  `job.cancel()` to cancel the running job directly.\n",
    "\n",
    "## Summary\n",
    "In this sample we created an HBASE application which connects to the Hadoop server, insetrted some rows into HBASE table and get the rows from the table.\n",
    "\n",
    "After submitting the application to the Streams service, we checked the application logs to see the progress.\n",
    "\n",
    "It is also possible to check the contents of the test table on the HBASE server with the following `hbase shell` command.\n",
    "\n",
    "```\n",
    "hbase shell\n",
    "scan 'streamsSample_lotr'\n",
    "```\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
